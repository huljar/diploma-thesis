After the protocol design phase (Chapter \ref{ch:protocol}) and the implementation with the simulator (Chapter \ref{ch:implementation}), the next step
is to evaluate the different approaches. As the primary goal of this thesis is to provide protection and resilience against malicious routers within
the \gls{noc}, the protocols were tested with varying attacker positions, attack probabilities, and routing strategies. The quality of a scheme
is determined through several metrics that indicate its performance for a given scenario, which are explained below.

The next section establishes notations and key terms that are used throughout this chapter. Afterwards, the environment and frame conditions for the
simulations are delineated (Section \ref{sec:environmenteval}). Following this, the employed attacker model is discussed (Section
\ref{sec:attackermodeleval}) and the configurable parameters for the simulations are explained (Section \ref{sec:configurations}). Subsequently,
the hyperparameters\footnote{The term \textit{hyperparameters} refers to those parameters whose value is determined through a number of preliminary
experiments and remains static for the main experiments.} are fixed through a series of representative experiments (Section
\ref{sec:hyperparamseval}), followed by the main evaluation where the different protocol variants and routing strategies are compared (Section
\ref{sec:perfcompeval}). Finally, an estimation of the required area overhead is presented in Section \ref{sec:areaoverhead} before giving a summary
of the results in Section \ref{sec:summaryeval}.

\section{Notation}\label{sec:notationeval}
To improve readability, abbreviations are introduced for the protocol variants and network coding modes. This facilitates their representation within
charts, diagrams, and tables.
\begin{itemize}
    \item \textbf{\Gls{ida}} stands for the \textit{individual authentication} protocol version,
    \item \textbf{\Gls{iwa}} represents the \textit{interwoven authentication} approach,
    \item \textbf{\Gls{fga}} denotes the \textit{full-generation authentication} variant,
    \item \textbf{UC} is short for \textit{uncoded}, i.e., the lack of network coding, and
    \item \textbf{G2C3} and \textbf{G2C4} are used for the two network coding variants that were explained in Section \ref{sec:designnc}.
\end{itemize}

These short forms are often combined with a routing strategy when the setup of an experiment is described. For instance, \gls{ida}-UC-\gls{dor} stands for uncoded
individual authentication using dimension order routing.

The term \textit{source flit} is used to refer to flits created by the processing elements before they are handled by the sender's network interface.
Consequently, the combinations obtained by network coding or \gls{mac} flits are not encompassed by this term. In the receiver's network interface,
the source flits are reconstructed by decoding, decrypting and verifying the incoming flits. Network interfaces only forward source flits towards
their local processing elements.

\section{Environment}\label{sec:environmenteval}
The simulator has a variety of input parameters that can be altered to influence its behavior and consequently the outcome of the simulations.
In this section, the parameters that are fixed for all conducted simulations are elaborated, such as flit generation patterns and simulation runtime. Table
\vref{tab:fixedparams} provides a concise overview of these parameters and their values.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{L|L}
        Parameter name & Value \\\hline
        \Gls{noc} dimensions & 8x8 (2D mesh) \\
        Clock frequency & 500 MHz \\
        Simulation runtime & \num{50000} cycles \\
        Warmup/cooldown time & 500 cycles \\
        Base network injection rate & 0.2 \\
        Flit destination selection & uniform random \\
        Pair generation & yes \\
    \end{tabulary}
    \caption[Static input parameters for all simulations]{The static, invariant input parameters of the simulator that are used across all
    experiments.}
    \label{tab:fixedparams}
\end{table}

When a simulation is executed, the first 500 cycles are considered warmup time. During this period, no statistics are recorded. This ensures that the
network is in a steady state and already saturated with flits once the recording starts. It is followed by the main simulation of \num{50000}
cycles where statistics are recorded normally. Finally, there are another 500 cooldown cycles at the end. They were appended to ensure that source flits
generated shortly before the end of the main simulation are not classified as lost flits simply because they were not granted enough time to reach their
destination. Thus, source flits generated during the main simulation and arriving at processing elements during the cooldown period are considered
successfully transmitted, while those generated during cooldown are not included in the statistics.

The base network injection rate describes the average number of flits injected into the network per clock cycle at each node, excluding \gls{arq}
flits and retransmissions. The creation rate of flits at the processing elements is adjusted accordingly for each protocol variant to keep the
injection rate constant. For instance, with \gls{ida}-G2C3, every source flit created at a particular processing element results in three flits
injected into the network due to network coding and the additional \gls{mac} flits.

The processing elements create source flits independently from each other. Furthermore, all processing elements use the same creation rate. The
selection of the flits' destinations is performed randomly over all network nodes (excluding the sender's own node). This ensures a uniform
distribution of sources and destinations across the \gls{noc}.

To allow for a fair comparison of the protocol versions, flits are always generated in pairs. This means that when a particular processing
element creates a flit, another one with the same destination is guaranteed to be created on the next clock cycle. This prevents long periods of
buffering for network coded \gls{ida} and \gls{fga} in the sender's network interface: with a pair of flits, a generation can be formed immediately.
This creation pattern is a realistic assumption as in practical applications, flits are usually generated from breaking a data packet down into
smaller parts (cf. Section \ref{sec:flitsfun}). These flits would then depart from the processing element consecutively and have the same
destination. The creation rate of flits is adjusted accordingly to reflect this pattern: for example, with \gls{ida}-G2C3, the probability to create a
pair would be set to $\frac{0.2}{6}$ to preserve the desired base network injection rate of 0.2. Table \vref{tab:creationrates} summarizes the
creation rates for all protocol variants.

\begin{table}
    \centering
    \bgroup
    \renewcommand{\arraystretch}{1.1}
    \begin{tabulary}{\textwidth}{C|C|C}
        Protocol       & Ratio pair : injected & Pair creation rate            \\\hline
        \gls{ida}-UC   & 1:4                   & $\frac{0.2}{4} = 0.05$        \\
        \gls{ida}-G2C3 & 1:6                   & $\frac{0.2}{6} \approx 0.033$ \\
        \gls{ida}-G2C4 & 1:8                   & $\frac{0.2}{8} = 0.025$       \\
        \gls{iwa}-UC   & 1:4                   & $\frac{0.2}{4} = 0.05$        \\
        \gls{iwa}-G2C3 & 1:6                   & $\frac{0.2}{6} \approx 0.033$ \\
        \gls{iwa}-G2C4 & 1:8                   & $\frac{0.2}{8} = 0.025$       \\
        \gls{fga}-G2C3 & 1:4                   & $\frac{0.2}{4} = 0.05$        \\
        \gls{fga}-G2C4 & 1:5                   & $\frac{0.2}{5} = 0.04$
    \end{tabulary}
    \egroup
    \caption[Creation rates of all protocol variants]{The source flit pair creation rates for all protocol variants. The second column displays the
    ratio of one generated source flit pair to the number of flits injected into the network resulting from this pair (excluding potential
    \glspl{arq} and retransmissions). The third column depicts the creation rates as they are adjusted to keep the base network injection rate
    at 0.2 across all variants.}
    \label{tab:creationrates}
\end{table}

Some of the parameters were adopted from the simulation setup that \citeauthor{moriam18activeattackers} \cite{moriam18activeattackers} have employed
in their experiments to render results comparable with their evaluations. These parameters include the \gls{noc} dimensions, the base network
injection rate, and the simulation runtime. The rationale for a clock speed of 500 MHz was outlined in Section \ref{subsec:clockfrequency}.

\section{Attacker Model}\label{sec:attackermodeleval}
As outlined in Section \ref{sec:attackermodelover}, the routers of the \gls{noc} are untrusted components that may be infected by a hardware trojan.
Such a compromised router has the capability to eavesdrop on the communication passing through it (passive attacker) and to maliciously drop or modify
flits (active attacker)\footnote{Routers are also able to inject arbitrary flits into the network to attempt a \gls{dos} attack through bandwidth
depletion. However, this is beyond the scope of this thesis and thus not considered here.}. Protection against an eavesdropper obtaining confidential
information is achieved through the employed encryption, so the remainder of this chapter focuses on the effects of active attacks.

For this thesis, eight of the routers are assumed to be infected, while the remaining ones operate normally. The rationale for not considering all
routers to be infected is that the presence of a hardware trojan entails a higher area occupation of the router due to the additional logic. If all
routers were malicious, it might drive the overall area requirement of the \gls{noc} to suspiciously high values, undermining the adversary's desire
to stay concealed (cf. Section \ref{sec:hardwaretrojans}).

The infected routers are assumed to not mount intelligent attacks, such as only compromising flits from a specific source. Rather, they randomly
attack passing flits based on their \textit{attack probability}. In such an event, the flit is either modified or completely dropped, with both cases
being equiprobable.

For the experiments, the eight infected routers were randomly selected from the 64 network nodes. To obviate large deviations of the recorded
statistics from the average due to their particular distribution, the main experiments were conducted for three different sets of attackers with the
results averaged over them\footnote{This is denoted by \enquote{all} in Table \ref{tab:inputparams} and subsequent experiment setup descriptions.}.
Figure \vref{fig:attackerpositions} illustrates the three selected distributions.

\begin{figure}
    \includegraphics[width=0.3\textwidth]{attacker-positions-1}\hfill
    \includegraphics[width=0.3\textwidth]{attacker-positions-2}\hfill
    \includegraphics[width=0.3\textwidth]{attacker-positions-3}
    \caption[Malicious router distributions]{The three distributions of 8 malicious routers over the 8x8 \gls{noc} that were used in experiments.}
    \label{fig:attackerpositions}
\end{figure}

\section{Configurations}\label{sec:configurations}
In addition to the static input parameters presented in Section \ref{sec:environmenteval}, there are several variable ones that constitute the setup
of an experiment. Naturally, they include the protocol variant and the routing strategy, but are not limited to those. Table \vref{tab:inputparams}
lists all the variable input parameters.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C}
        Parameter name & Value range & Placeholder \\\hline
        Protocol variant & $\{\text{\gls{ida}}, \text{\gls{iwa}}, \text{\gls{fga}}\}$ & \pProtVar{} \\
        Network coding & $\{\text{UC}, \text{G2C3}, \text{G2C4}\}$ & \pNCMode{} \\
        Routing strategy & $\{\text{\gls{dor}}, \text{\gls{dm}}, \text{\gls{romm}}, \text{\gls{ramm}}\}$ & \pRStrat{} \\
        No. of encryption modules & $\mathbb{N}^*$ & \pEncMods{} \\
        No. of authentication modules & $\mathbb{N}^*$ & \pAuthMods{} \\
        \Gls{arq} limit & $\{1, 2\}$ & \pARQLimit{} \\
        \Gls{arq} timeout in cycles & $\mathbb{N}^*$ & \pARQTimeout{} \\
        Port queue size in flits & $\mathbb{N}^* \cup \infty$ & \pRQSize{} \\
        Set of attackers & $\{1, 2, 3, \text{all}, \text{none}\}$ & \pAttackerSet{} \\
        Attack probability & $[0, 0.5]$ & \pAttackProb{} \\
    \end{tabulary}
    \caption[Variable input parameters for the simulations]{The variable input parameters for the simulations. The third column shows the placeholders
    that are used in subsequent experiment setups to represent the corresponding parameters.}
    \label{tab:inputparams}
\end{table}

Each network interface contains a number of encryption and authentication modules. On the one hand, there need to be enough modules to process both
departing and arriving flits quickly without incurring congestions. On the other hand, each additional module entails a higher area requirement for
the network interfaces. Thus, a reasonable trade-off between latency and area needs to be determined. This hyperparameter is examined in Section
\ref{subsec:numcryptomodules}.

The \gls{arq} limit is the number of \glspl{arq} that are allowed to be issued per transmission unit (see Section \ref{subsec:arqretransmissions}).
Only the values 1 and 2 are considered here for multiple reasons. First, the more \glspl{arq} are allowed, the larger the \glspl{rtb} need to be:
since additional \glspl{arq} are only sent if the preceding ones did not yield successful retransmissions, senders need to retain flits in their
\glspl{rtb} over a longer period\footnote{A detailed calculation of the \gls{rtb} size requirements is given in Section \ref{sec:areaoverhead}.}.
Second, if more \glspl{arq} and consequently more retransmissions are injected into the network, congestions become more likely, which in turn may
induce timeouts for other transmissions.

The value of the \gls{arq} timeout is the first hyperparameter that is fixed through an experiment (Section \ref{subsec:arqtimeouts}). As explained in
Section \ref{subsec:arqretransmissions}, it represents the amount of clock cycles after receiving a flit from a particular transmission unit until the
remainder of this unit is considered lost.

The sizes of the port queues of the routers are another hyperparameter. Unfortunately, it could only be determined for \gls{dor}. The absence of
virtual channels in the routers (cf. Section \ref{subsec:singlecyclerouting}) incurs deadlocks for the other routing strategies if a limited queue
size is enforced. For instance, \gls{romm} routing necessitates two virtual channels (one for each phase) to guarantee deadlock freedom
\cite[4]{nesson95romm}. \Gls{dor}, however, is not affected by deadlocks, even without virtual channels \cite[9]{ni93routingsurvey}. Thus, as a
workaround, a hard queue size limit is only implemented for \gls{dor}\footnote{With a hard queue size limit, routers must delay flits that are
to be sent via a congested link, as they would be discarded otherwise.}. For the other strategies, congestion signals are still sent out once a queue
has reached the given size, but it will continue to accept incoming flits. While \gls{romm}, being oblivious, ignores these signals, \gls{dm} and
\gls{ramm} attempt to avoid congested links as much as possible. In Section \ref{subsec:portqueuesizes}, the experiment to determine the size limit
for \gls{dor} is described.

Finally, the properties of the attacking routers may be configured via the set of attackers and their attack probability. The set of attackers refers
to one of the three sets described in Figure \ref{fig:attackerpositions}. A value of \textit{all} indicates that the experiments were conducted for
each of the sets independently and the results are averaged across the three settings. If no attackers are present, \textit{none} is used. The attack
probability parameter defines the likelihood for a malicious router to attack a flit as described above (Section \ref{sec:attackermodeleval}).

\section{Determining The Hyperparameters}\label{sec:hyperparamseval}
\subsection{ARQ Timeouts}\label{subsec:arqtimeouts}
The first hyperparameter that is fixed through an experiment is the number of cycles for an \gls{arq} timeout. In Section
\ref{subsec:arqretransmissions}, it was mentioned that two different timeout values exist: in addition to the inter-arrival timeout, there is another,
higher value that is used after an \gls{arq} was issued to await the answer (the post-\gls{arq} timeout). However, only the former
is empirically determined, while the latter is calculated from the inter-arrival timeout, the Manhattan distance between the
two affected communication partners, and the \gls{rtb} lookup time. More precisely, if $t_1$ is the inter-arrival timeout, $t_2(S, D)$ is the post-\gls{arq} timeout for a
particular source $S$ and destination $D$, $d$ is the Manhattan distance between the two nodes, and $l$ is the \gls{rtb} lookup time, then $t_2(S, D)
= t_1 + 2d + l$. Figure \vref{fig:arqtimeoutscalc} illustrates this calculation. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{arq-timeouts-calc}
    \caption[Example of the post-ARQ timeout calculation]{Example for the calculation of post-\gls{arq} timeouts. With a Manhattan distance of 4
    between source $S$ and destination $D$, a given inter-arrival timeout $t_1$, and an \gls{rtb} lookup time of $l$ cycles, the post-\gls{arq}
    timeout $t_2(S, D)$ is computed as $t_1 + l + 2 \cdot 4 = t_1 + l + 8$ cycles.}
    \label{fig:arqtimeoutscalc}
\end{figure}

Thus, the purpose of this experiment is to determine a suitable value for $t_1$. The idea is that in a network devoid of attackers, ideally no
\glspl{arq} are issued since no flits are lost. However, due to random deviations from the average flit injection rate, the network load varies over
time and congestions in some routers
may occur. The resulting increased transmission delays may be high enough to trigger timeouts even when an \gls{arq} is not necessary. Sporadic
occurances of such cases cannot be ruled out, but should rarely happen. However, simply increasing the timeout until these cases vanish is undesirable
for two reasons. First, a high timeout directly corresponds to high latencies when flit losses necessitate \glspl{arq}. Second, the later an \gls{arq}
is issued, the larger the \gls{rtb} of the communication partner needs to be so that the flits in question are not already overwritten when the
\gls{arq} arrives. The goal of this experiment is to find a reasonable middle ground: the smallest timeout that does not entail a significant number of
unnecessary \glspl{arq} will be used for the subsequent evaluations.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{ida}   & varying    & 5           & 15           & unlimited  & 1            & varying        & \gls{dor}  & none            & 0              \\
    \end{tabulary}
    \caption[Input parameters for ARQ timeouts experiment]{The input parameters for the simulator in the \gls{arq} timeouts experiment.}
    \label{tab:setuparqtimeouts}
\end{table}

Since $t_1$ is the first parameter to be fixed, the other input values for the simulation are estimates. They are summarized in Table
\vref{tab:setuparqtimeouts}. The tests are for the most part independent of the protocol variant as the same injection rate is used for all of them.
Hence, \gls{ida} was selected as it features the largest variety of transmission unit sizes (from 2 for UC up to 8 for G2C4) and all \glspl{arq} are
issued per transmission unit. The number of crypto modules was set to a sufficiently high value to ensure that no congestions occur inside the network
interfaces. Similarly, the router port queue sizes are not limited as no fitting value was determined yet. \Gls{dor} is employed since it is used as
the baseline for all experiments before evaluating the effects of other routing strategies.

\begin{figure}
    \centering
    \input{gnuplot/plots/arqtimeouts}
    \caption[Results for ARQ timeouts experiment]{long}
    \label{fig:resultsarqtimeouts}
\end{figure}

Figure \vref{fig:resultsarqtimeouts} presents the number of \glspl{arq} issued for $t_1 \in [3, 15]$ clock cycles. The values are shown in relation to
the number of created source flits instead of the number of transmission units as the size of the latter varies significantly depending on the network
coding scheme. For timeout values of 12 or greater, less than 1 \gls{arq} per 100 source flits is sent, which is considered sufficiently small here.
Hence, $t_1 = 12$ is chosen and used in all future experiments.

\subsection{Number Of Crypto Modules}\label{subsec:numcryptomodules}
The second experiment concerns itself with the number of required encryption and authentication modules in the network interfaces. Here, a
reasonable trade-off between occupied chip area and performance needs to be determined: there should be just enough modules to keep the waiting time
of flits for a free module low.

In Figure \ref{fig:omnetni}, it was shown that the flits from four queues compete for access: two for encryption modules and two for authentication
modules. The idea of this experiment is to measure the time (in clock cycles) that flits are enqueued before they are granted access to a crypto
module. In addition to the average, the maximum queue time was investigated as well to take periods of increased network traffic into account. Even
during such periods, the flits should not suffer unreasonably high delays.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        varying     & varying    & varying     & varying      & unlimited  & 1            & 12             & \gls{dor}  & 1               & 0.2            \\
    \end{tabulary}
    \caption[Input parameters for number of crypto modules experiment]{The input parameters for the simulator in the experiment to determine the
    number of required crypto modules.}
    \label{tab:setupnumcrypto}
\end{table}

Table \vref{tab:setupnumcrypto} shows the input parameters used for this experiment. Since the internal structure of the network interfaces and the
number of cycles for authentication vary considerably depending on the protocol variant, all of them were investigated and compared. The rationale for
unlimited router port queue sizes is the same as in the \gls{arq} timeout experiment (see above). The \gls{arq} limit is set to 1 for the same reason
that \gls{dor} is used as the routing strategy: they are baseline values for all experiments until the effects of varying them are investigated later
on. The \gls{arq} timeout is set to 12, which is the value identified in the previous experiment (Section \ref{subsec:arqtimeouts}). Attackers
with a medium attack probability are added as their presence entails an increase in required decryptions and \gls{mac} computations: if an integrity
breach is detected, both these actions need to be executed for the subsequent retransmissions as well.

The minimum waiting time of a flit is one cycle: as the queues provide synchronization with the global clock, even flits that arrive at an empty queue
can be sent out at the earliest on the next clock tick. Furthermore, the fact that at most one flit can be sent out from a queue per cycle induces an
upper bound on the number of required crypto modules. For encryption, four modules always suffice as processing a flit takes two cycles and at most two
flits can be distributed among the modules per cycle (one from the encryption and one from the decryption queue). The upper bound for authentication
modules is calculated in the same manner, but depends on the protocol variant. For \gls{ida} and \gls{iwa}, it is 12 and 10 modules, respectively, as
the authentication process requires six and five cycles, respectively. \Gls{fga} operates slightly differently because two flits are required for a
single authentication procedure. Thus, an authentication module is busy for 11 cycles (one to wait for the second flit, then 10 for the \gls{mac}
computation). Hence, at most 11 modules are required for this variant.

\begin{figure}
    \centering
    \begin{tabular}{ll}
        \input{gnuplot/plots/encmodules-ida} & \input{gnuplot/plots/authmodules-ida.tex} \\
        \input{gnuplot/plots/encmodules-iwa} & \input{gnuplot/plots/authmodules-iwa.tex} \\
        \input{gnuplot/plots/encmodules-fga} & \input{gnuplot/plots/authmodules-fga.tex}
    \end{tabular}
    \caption[Results for number of crypto modules experiment]{Results for the experiment to determine the number of required crypto modules. The
    number of encryption modules (left column) and authentication modules (right column) is shown in relation to the maximum and average wait times of
    enqueued flits. Each row represents one protocol variant.}
    \label{fig:resultscryptomodules}
\end{figure}

Figure \vref{fig:resultscryptomodules} presents the results of the experiment. For each protocol variant and all viable numbers of encryption and
authentication modules, the maximum and average wait times of flits are depicted. The criterion for having enough modules is that the maximum wait
time should not exceed 10 cycles, while the average should be very close to the minimum of a single cycle. Thus, three encryption and nine
authentication modules are chosen for all subsequent experiments\footnote{This also means that the sizes of the queues in front of the crypto modules
(cf. Figure \ref{fig:omnetni}) do not need to exceed around 10 flits.}.

\subsection{Port Queue Sizes}\label{subsec:portqueuesizes}
The final hyperparameter that is determined is the size of the routers' port queues. This value potentially impacts the transmission delays for
oblivious strategies and has an influence on the routing decisions for adaptive strategies. However, as explained in Section \ref{sec:configurations},
the queue limit is only determined and enforced for \gls{dor} due to the susceptibility of the other strategies to deadlocks. For the adaptive
ones, the determined value is used as a congestion threshold instead of a size limit.

Once again, small queues are preferable with regard to the occupied chip area of the routers, but larger queues are advantageous to achieve lower
transmission latencies. To prevent flits from being discarded due to oversaturation of the network, the local queues of the routers are always
assumed to be unlimited in size. Since \gls{dor} delays flits that are to be routed through a congested link, the flits will accumulate there if the
port queue sizes are too restrictive. Thus, in the experiment, the maximum and average lengths of both the port queues and the local queues are
investigated for varying size limits of the former.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{ida} & varying & 3 & 9 & varying & 1 & 12 & \gls{dor} & 1 & 0.2 \\
    \end{tabulary}
    \caption[Input parameters for router queue sizes experiment]{long}
    \label{tab:setupqueuesizes}
\end{table}

The input parameters for the simulator are given in Table \vref{tab:setupqueuesizes}. As the results should be mostly independent of the protocol
variant due to using the same base network injection rates for all of them, \gls{ida} is used as a reference. For the number of crypto modules and the
\gls{arq} timeout, the results of the previous experiments are employed. Attackers are once again present as they may have a considerable impact on
the network load.

\begin{figure}
    \centering
    \begin{tabular}{ll}
        \input{gnuplot/plots/queuelengths-ports} & \input{gnuplot/plots/queuelengths-local}
    \end{tabular}
    \caption[Results for router queue lengths experiment]{long}
    \label{fig:resultsqueuelengths}
\end{figure}

The results are shown in Figure \vref{fig:resultsqueuelengths}. The queue lengths were examined for size restrictions ranging from one to ten flits,
as well as unlimited sizes for comparison. Unsurprisingly, the maximum length of the port queues matches the imposed limit (except for the unlimited
case). Their average length stays relatively constant at approximately 0.4 flits. The more interesting results involve the local queues: with small
size limits on the port queues, flits accumulate there faster than the network can handle them and both maximum and average lengths escalate quickly.
A size limit of six flits was chosen for multiple reasons. First, the average length of the local queues is around one flit, which indicates that even
sporadic accumulations (the highest being 75 flits for G2C4) are dispelled relatively quickly. Second, a higher limit only marginally improves both
average and maximum local queue lengths and is thus not considered worth the additional required chip area.

\section{Performance Comparisons}\label{sec:perfcompeval}
After the preliminary experiments to determine the hyperparameters for the simulations were finished, the main performance evaluations of the protocol
variants and routing strategies are tackled. In the next section, various criteria are established and explained that indicate the performance aspects
of a given configuration. Then, the protocol variants are compared under these criteria for varying attack probabilities of the malicious routers.
Afterwards, the most promising variant is evaluated for each of the presented routing strategies to examine their effects on the performance. Finally,
the consequences of increasing the \gls{arq} limit to 2 are investigated.

\subsection{Criteria}
To facilitate comparisons of the obtained results with previous research at the Chair of Privacy and Data Security of the TU Dresden, the metrics of
\citeauthor{moriam18activeattackers} \cite{moriam18activeattackers} are all adopted for the evaluation here. Those are the acceptance rate, the
information rate, and the residual error probability. As an additional metric, the average end-to-end latency of source flits is employed. The following list elaborates on the
details of these metrics:
\begin{itemize}
    \item \textbf{Acceptance rate.} The base network injection rate specifies the number of flits that are injected into the network per clock cycle
        per node. However, it excludes \glspl{arq} and retransmissions (cf. Section \ref{sec:environmenteval}), whose number rises with increasing
        attack probabilities. By including them, the total network injection rate is obtained, which is called acceptance rate here. It provides an
        indicator for both the frequency of \glspl{arq} and retransmissions as well as the network load.
    \item \textbf{Information rate.} The information rate is the quotient of the amount of created source flits and the total number of flits injected
        into the network. Thus, it illustrates the overhead of authentication, network coding, \glspl{arq}, and retransmissions that the protocol
        imposes for transmitting information from one processing element to another.
    \item \textbf{Residual error probability.} This represents the portion of source flits that were not transmitted successfully to their destination
        processing elements despite exhausting the allowed number of \glspl{arq}. Thus, it serves as a crucial indicator of the reliability and
        resilience that the protocol aims to add to the communications.
    \item \textbf{Average end-to-end latency.} As introduced in Section \ref{sec:networkonchipfun} and mentioned numerous times throughout this
        thesis, low transmission latencies are an essential performance criterion for \glspl{noc}. The average end-to-end latency captures the mean
        transmission time of source flits from their generation at the sending processing elements to their arrival at the receiving ones in clock
        cycles.
\end{itemize}

\subsection{Protocol Variants}\label{subsec:protocolvariantseval}
All protocol variants defined in Section \ref{sec:theprotocol} are compared with respect to the performance criteria outlined above. This experiment
aims to identify the most promising one of them. The input parameters of the simulator were chosen according to the results of the preliminary
experiments from Section \ref{sec:hyperparamseval}. The \gls{arq} limit of 1 and the \gls{dor} routing strategy are employed as baselines for the
comparisons once more. The full list of input parameters is given in Table \vref{tab:setupprotvarexperiment}.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        varying & varying & 3 & 9 & 6 & 1 & 12 & \gls{dor} & all & varying \\
    \end{tabulary}
    \caption[Input parameters for protocol variant experiment]{long}
    \label{tab:setupprotvarexperiment}
\end{table}

The results are presented in Figure \vref{fig:resultsprotvarexperiment}. The four criteria -- acceptance rate, information rate, residual error
probability, and average end-to-end latency -- were investigated for various attack probabilities ranging from 0 to 0.5 to illustrate both the impact
of attackers on the communications and the capability of the different protocol variants to mitigate this impact.

\begin{figure}
    \centering
    \begin{tabular}{ll}
        \input{gnuplot/plots/main-acceptancerate} & \input{gnuplot/plots/main-informationrate} \\
        \input{gnuplot/plots/main-residualerror} & \input{gnuplot/plots/main-endtoendlatency}
    \end{tabular}
    \caption[Results for protocol variant experiment]{long}
    \label{fig:resultsprotvarexperiment}
\end{figure}

The acceptance rate rises with increasing attack probabilities as more \glspl{arq} and retransmissions become necessary. It starts at slightly
above the base network injection rate of 0.2 even without the presence of malicious routers. This is due to a few sporadic \glspl{arq} that are
triggered by timeouts stemming from temporarily increased network loads; the experiment in Section \ref{subsec:arqtimeouts} already confirmed that
this is possible. With rising attack probabilities, different growth rates can be observed for the protocol variants, indicating that some entail more
\glspl{arq} and retransmissions than others. Unsurprisingly, the uncoded versions are in the lead as they cannot recover from flit loss or
modifications without issuing an \gls{arq}. Following them are the \gls{fga} variants. With only one \gls{mac} for a whole generation, an attack on
the carrying flit always necessitates a retransmission. The lowest acceptance rates are achieved by network coded \gls{ida} and \gls{iwa} as they are
resilient to sporadic attacks and no single modification or loss within a generation forces an \gls{arq}. In general, the G2C4 versions perform better
than G2C3 due to their increased redundancy in the transmitted flits.

The information rate directly reflects the overhead that each protocol variant imposes on the transmissions (cf. Table \ref{tab:creationrates}). Thus,
for no attackers, it is around 0.5 for the uncoded protocols and \gls{fga}-G2C3, as they cause two flits to be injected into the network per source
flit. For \gls{ida} and \gls{iwa} in their G2C4 variants, the overhead is twice as high, resulting in half the information rate. With increasing
attack probabilities, the number of \glspl{arq} are retransmissions rises, which is reflected in declining information rates. In addition, as the
acceptance rate and information rate both indicate the portion of \glspl{arq} and retransmissions of the total traffic, high fluctuations in the
former are accompanied by large variations of the latter.

The residual error probability is the main indicator for the ability of the protocol to mitigate the impact of attackers. Unsurprisingly, a lack of
adversaries results in no residual errors for all variants, but this begins to deviate quickly as the attack probabilities are increased. As expected,
the uncoded versions are both at the worse end of the spectrum. Peculiarly, for \gls{ida}, the network coded versions perform even worse than the
uncoded one, which contrasts with the expectation of their greater resilience. This is likely due to a combination of three properties: first, network
coded \gls{ida} binds two source flits within a single generation, so on average there are only 0.5 \glspl{arq} available per source flit (assuming an
\gls{arq} limit of 1). Second, it comprises the largest transmission units (6 and 8 flits for G2C3 and G2C4, respectively), so the probability of at
least one of these flits being attacked is relatively high. Third, four flits are required to arrive intactly per generation, which is the largest
amount out of all protocol variants. Due to the large transmission units, the necessity of further \glspl{arq} might only be detected when
their limit was already reached, leading to both source flits of the affected generation being lost. This line of thought also explains why network
coded \gls{iwa} performs best: it has the smallest transmission units of all network coded variants, each source flit is comprised within its own
generation, and one \gls{arq} is available for every source flit. \Gls{fga} lying in the middle is explained by the susceptibility of the \gls{mac}
flits: if such a flit is attacked, the complete generation must be retransmitted, as it authenticates both source flits together. Moreover, \gls{fga}
suffers from the same deficit as \gls{ida}: one failing generation entails two lost source flits.

The average end-to-end latency reflects the added expenditure of time required by the protocols to transmit information. Overall, higher attack
probabilities result in increased latencies due to the higher amount of retransmissions. It is important to note that lost source flits, i.e., those
counting towards the residual error probability, are ignored in this statistic as they do not have an end-to-end latency. This also explains the
turnaround at the highest attack probabilities as the retransmissions become increasingly likely to fail. As expected, \gls{fga} has by far the
highest average latencies across all investigated attack probabilities. The reason for this is the duration of the authentication procedure: with 10
cycles, it consumes more time than for \gls{ida} and \gls{iwa} by a large margin. Furthermore, receivers need to obtain enough flits to decode the
generation before the \gls{mac} computation can begin. The uncoded protocol variants have the lowest latencies since no delays are imposed by network
encoding and decoding.

Overall, the network coded versions of \gls{iwa} perform best. While the redundancy entailed by network coding leads to a relatively low information
rate, they provide the most reliable transmissions by a large margin and generate the lowest network load with a competitive average latency. For
these reasons, \gls{iwa} is chosen to be investigated further in the following section. As the results only varied minimally among the three different
attacker sets, only the first one will be used for the remaining experiments to simplify the simulation process.

\subsection{Routing Strategies}
After identifying \gls{iwa} as the most promising variant, it is subjected to further investigation. In the next experiment, the effect of substituting
the routing strategy is examined. All variants of \gls{iwa} are tested with each of the three other routing strategies -- \gls{dm}, \gls{romm}, and
\gls{ramm}. The full simulation setup is shown in Table \vref{tab:setuproutingstratexperiment} and the results are presented in Figure
\vref{fig:resultsroutingstratsexperiment}.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{iwa} & varying & 3 & 9 & 6 & 1 & 12 & varying & 1 & varying \\
    \end{tabulary}
    \caption[Input parameters for routing strategies experiment]{long}
    \label{tab:setuproutingstratexperiment}
\end{table}

\begin{figure}
    \begin{tabular}{cc}
        \input{gnuplot/plots/strategies-acceptancerate} & \input{gnuplot/plots/strategies-informationrate} \\
        \input{gnuplot/plots/strategies-residualerror} & \input{gnuplot/plots/strategies-endtoendlatency}
    \end{tabular}
    \caption[Results for routing strategies experiment]{long}
    \label{fig:resultsroutingstratsexperiment}
\end{figure}

The acceptance rates are revealed to be mostly unaffected by the choice of routing strategy, except for the uncoded case. There, all of the dynamic
strategies lead to noticeably higher values than the static \gls{dor}. A likely explanation of this phenomenon is that the usage of different paths
for flits in the same transmission unit increases the probability that at least one of these flits encounters an attacker. As the uncoded protocol
version does not tolerate any modifications or losses, it leads to more \glspl{arq} and retransmissions than with static routes. Interestingly, the
dynamic strategies were only able to lower the acceptance rate slightly for very high attack probabilities when network coding is employed. This may
be caused by more network traffic being routed through the center of the \gls{noc}, leading to congestions in this area. To verify this assumption,
the router workload distributions over the network were analyzed (see below).

The information rates largely reflect the same impact that the routing strategies had on the acceptance rates. For uncoded \gls{iwa}, the dynamic ones
perform worse than \gls{dor}, while the margin is miniscule for the network coded variants.

Similar observations are made for the residual error probabilities. The dynamic strategies have a negative impact on the reliability of the uncoded
variant, likely for the same reasons that were outlined above. With network coding, the effects are almost unrecognizable for low and medium attack
probabilities. However, as they rise above 0.2, the envisioned advantages of dynamic routing (cf. Figure \ref{fig:circumventattackers}) come to
fruition and a considerable improvement is observed.

In terms of average end-to-end latency, there is no clear best or worst strategy. They all perform similarly, but the discrepancies between the
protocol variants are less severe for the dynamic strategies. Overall, \gls{dm} and \gls{ramm} seem to enable slightly faster transmissions than
\gls{dor} and \gls{romm}.

As mentioned above, the workload distribution among the routers varies with the different routing strategies. Thus, using the example of
\gls{iwa}-G2C3, those discrepancies were analyzed and visualized in heatmaps. The simulation setup for this experiment is given in Table
\vref{tab:setuproutingheatmaps} and the results are presented in Figure \vref{fig:resultsroutingstratheatmaps}.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{iwa} & G2C3 & 3 & 9 & 6 & 1 & 12 & varying & 1 & 0.2 \\
    \end{tabulary}
    \caption[Input parameters for routing heatmap comparison]{long}
    \label{tab:setuproutingheatmaps}
\end{table}

\begin{figure}
    \begin{tabular}{cccc}
        \input{gnuplot/plots/heatmap-iwa-g2c3-dor} & \input{gnuplot/plots/heatmap-iwa-g2c3-dm} &
        \input{gnuplot/plots/heatmap-iwa-g2c3-romm} & \input{gnuplot/plots/heatmap-iwa-g2c3-ramm} \\
        (a) & (b) & (c) & (d) \\
    \end{tabular}
    \caption[Heatmaps of the routers for different routing strategies]{Heatmaps of the routers for different routing strategies.}
    \label{fig:resultsroutingstratheatmaps}
\end{figure}

The findings confirm the assumption that the dynamic strategies route more traffic through the center of the network. For instance, if the bottom
left and top right node were to communicate, \gls{dor} would force the traffic to be routed along the edges of the \gls{noc}, while the dynamic
strategies favor more jagged paths on average. However, the results reveal that even \gls{dor} effects traffic concentrations in the center, although
less severe. A major contributing factor to this phenomenon is the uniform traffic pattern that is employed for the experiments; nodes closer to the
center generate and receive just as many flits as the fringe nodes, which naturally leads to more paths involving central routers. Hence, in scenarios
with higher injection rates, \gls{dor} may prove to be favorable as it causes less congestions in this area. However, with non-uniform generation
patterns where the fringe nodes produce a higher traffic volume, the advantages of dynamic routing are likely to surface more clearly.

Finally, the impact of a dynamic routing strategy on protocols other than \gls{iwa} was investigated. For this purpose, \gls{dm} was selected since it
performed marginally better for uncoded \gls{iwa} while being on the same level as \gls{romm} and \gls{ramm} when network coding was involved. In
Table \vref{tab:setuproutingdorvsdm}, the input parameters for the simulator are listed, while the results are presented in Figure
\vref{fig:resultsroutingdorvsdm}.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{ida}, \gls{fga} & varying & 3 & 9 & 6 & 1 & 12 & \gls{dor}, \gls{dm} & 1 & varying \\
    \end{tabulary}
    \caption[Input parameters for comparing DOR and DM]{long}
    \label{tab:setuproutingdorvsdm}
\end{table}

\begin{figure}
    \begin{tabular}{cc}
        \input{gnuplot/plots/dorvsdm-acceptancerate} & \input{gnuplot/plots/dorvsdm-informationrate} \\
        \input{gnuplot/plots/dorvsdm-residualerror} & \input{gnuplot/plots/dorvsdm-endtoendlatency}
    \end{tabular}
    \caption[Results for the DOR and DM comparison]{long}
    \label{fig:resultsroutingdorvsdm}
\end{figure}

Similar to the earlier results for \gls{iwa} (Figure \ref{fig:resultsroutingstratsexperiment}), DM provides a benefit only in conjunction with network
coding while deteriorating the performance in its absence. This result matches the envisioned impact of dynamic routing (cf. Section
\ref{subsec:routingclassification}) since only the network coded protocols benefit from partially circumventing malicious routers. However, this
advantage is partially mitigated by the increased traffic clustering that these strategies entail (cf. Figure \ref{fig:resultsroutingstratheatmaps}).

\subsection{Increased ARQ Limit}
A variable parameter that was not touched so far is the \gls{arq} limit. Hence, the final experiment concerns itself with the effects of allowing up
to two \glspl{arq} per transmission unit. As explained in Section \ref{sec:configurations}, higher values are not considered since they entail
unreasonably large \glspl{rtb}. The selected protocol is \gls{iwa} as it proved to be the most promising variant. \Gls{dor} is the routing strategy of
choice to preserve comparability with the results from Section \ref{subsec:protocolvariantseval}; moreover, the dynamic strategies did not lead to a
distinct performance gain. Table \vref{tab:setuparqlimits} summarizes the full list of input parameters and Figure \vref{fig:resultsarqlimits}
visualizes the simulation results.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C|C|C|C|C|C|C|C}
        \pProtVar{} & \pNCMode{} & \pEncMods{} & \pAuthMods{} & \pRQSize{} & \pARQLimit{} & \pARQTimeout{} & \pRStrat{} & \pAttackerSet{} & \pAttackProb{} \\\hline
        \gls{iwa} & varying & 3 & 9 & 6 & varying & 12 & \gls{dor} & 1 & varying \\
    \end{tabulary}
    \caption[Input parameters for comparing different ARQ limits]{Input parameters for comparing ARQ limits 1 and 2 for \gls{iwa}.}
    \label{tab:setuparqlimits}
\end{table}

\begin{figure}
    \begin{tabular}{cc}
        \input{gnuplot/plots/arqlimits-acceptancerate} & \input{gnuplot/plots/arqlimits-informationrate} \\
        \input{gnuplot/plots/arqlimits-residualerror} & \input{gnuplot/plots/arqlimits-endtoendlatency}
    \end{tabular}
    \caption[Results for the ARQ limit comparison]{ARQ limit 1 and 2 comparison.}
    \label{fig:resultsarqlimits}
\end{figure}

Expectedly, the acceptance rates are substantially higher for an \gls{arq} limit of 2 due to the increased number of retransmissions. Hence, a higher
limit directly corresponds to an increase in network load. A similar development is reflected in the information rates: the amount of \glspl{arq} and
retransmissions in relation to the total amount of flits injected into the network decreases considerably. In this sense, incrementing the \gls{arq}
limit did not elevate the protocol's performance.

However, the positive impact of the higher limit comes to fruition when analyzing the residual error probabilities. For all variants, a significant
improvement can be observed for low and medium attack probabilities. The effect is most striking for the uncoded variant, cutting the number of
unsuccessfully transmitted source flits by more than 50\% at an attack probability of 0.1. For high attack probabilities, the positive effect
diminishes and even entails more errors for the uncoded protocol. This is likely due to the increased amount of \glspl{arq} and retransmissions
that traverse the network causing additional congestions and thus leading to failures for other transmission units in the process.

The average end-to-end latency increases significantly for the incremented \gls{arq} limit. This indicates that with rising attack probabilities,
larger portions of transmissions only succeed due to the possibility of secondary \glspl{arq}. The effect is most apparent for the uncoded protocol, which
produced the steepest curve. As the likelihood of attacks surpasses 0.2, the average end-to-end latency spikes up to over 400 cycles, indicating that the
network becomes unable to handle the rising traffic volume quickly enough and that flits begin to accumulate at the routers' local queues. This matches
the development of the acceptance rate, which also exhibits a prominent upsurge beyond attack probabilities of 0.2.

\section{Area Overhead}\label{sec:areaoverhead}
The network coding, encryption, and authentication layers naturally increase the area requirement of the \gls{noc}. In this section, the percentage of
these components in relation to the remainder of the system is estimated.

Network coding requires matrix multiplications in the domain $GF(2^4)$ to be computed (cf. Section \ref{sec:designnc}). According to
\citeauthor{moriam18activeattackers}, an efficient implementation can be achieved by using lookup tables to store all possible products of such
multiplications \cite[6]{moriam18activeattackers}. For \gls{ida} and \gls{fga}, 36 parallel lookups are required, while only 20 are necessary for
\gls{iwa} due to the shorter data parts of the payloads \cite[6]{moriam18activeattackers}. Assuming a size of 118 gate equivalents (\gls{ge}) per
table \cite[6]{moriam18activeattackers}, this accumulates to 4248 \gls{ge} in order to compute one combination in a single clock cycle. As the decoder
is a separate module in the network interface design (see Figure \ref{fig:omnetni}), it requires another 4248 \gls{ge}. Thus, for each interface,
network coding implies an area overhead of 8496 \gls{ge} (excluding any additional wiring required).

The cryptographic modules, however, occupy significantly more area. The authors of PRINCE have found their algorithm to require 8260
\gls{ge}\footnote{This value was obtained with Nangate 45 nm Generic technology and a unit delay of 1000. Both lower and higher values were calculated
with other technologies.} \cite[16]{borghoff12prince}. Thus, for three encryption and nine authentication modules, a total of twelve parallel
instances are necessary, resulting in \num{99120} \gls{ge} per network interface.

Finally, the \glspl{rtb} that are necessary for retransmissions also increase the area overhead. Their size depends on several factors:
\begin{itemize}
    \item \textbf{\Gls{noc} dimensions.} For larger network, there are higher maximum distances between nodes. Thus, \glspl{arq} may arrive later and
        flits need to be stored for a longer period of time. The equation below is established for an 8x8 \gls{noc} since this was used in all
        experiments.
    \item \textbf{\Gls{arq} limit.} If more than one \gls{arq} is allowed, the required storage duration increases as flits still need to be present
        when the secondary \gls{arq} arrives.
    \item \textbf{Network load.} A higher network load entails more congestions in the routers, which may delay both the delivery of the initial flits
        as well as the \glspl{arq}. However, such congestions are volatile and hard to estimate, so for the following calculation, they are not taken
        into account.
\end{itemize}

With \gls{noc} dimensions of 8x8, the highest Manhattan distance between two nodes is $d = 14$ hops. For an inter-arrival timeout of $t_1 = 12$ cycles, the
highest post-\gls{arq} timeout is consequently $t_2 = t_1 + 2 \cdot 14 + 2 = 42$ cycles for network coded protocols (cf. Section
\ref{subsec:arqtimeouts}). Assuming \gls{ida}-G2C4 as the protocol variant (since it has the largest transmission units) and no network congestion,
the 8 flits that comprise a generation arrive within 8 consecutive clock cycles at the receiver. Thus, in case the last flit is lost in transit, an
\gls{arq} will be issued $d + 7 + t_1$ cycles after the first flit was injected into the network, and it will arrive at the sender after $2d + 7 +
t_1 = 47$ cycles. Hence, each flit needs to reside for at least 47 cycles within the \gls{rtb} for an \gls{arq} limit of 1. With a base network
injection rate of 0.2, 9.4 further flits are on average injected into the network during this timespan. Thus, an \gls{rtb} size of 10 flits is
required to have no requested flit already overwritten once the \gls{arq} arrives. For a limit of 2, the duration until the second \gls{arq}
arrives needs to be taken into account. Assuming that with the first \gls{arq}, one flit was retransmitted and once more lost in transmit, this
timespan amounts to $d + 7 + t_1 + t_2 + d = 4d + 2t_1 + 9 = 89$ cycles, during which 17.8 more flits are injected into the network on average. Hence,
for an \gls{arq} limit of 2, \glspl{rtb} with a size of 18 flits are necessary.

\begin{table}
    \centering
    \begin{tabulary}{\textwidth}{C|C|C||C}
        Crypto modules & Network coding & \glspl{rtb} & Total \\\hline
        \multirow{2}{=}{\num{99120} \gls{ge}} & \multirow{2}{=}{8496 \gls{ge}} & \multirow{2}{=}{335.25 B} & \num{107616} \gls{ge} \\
                                              & & & 335.25 B
    \end{tabulary}
    \caption[Area overhead per network interface]{The area overhead that the protocol imposes per network interface. While the circuit sizes of the
    crypto modules and the network coding tables are given in \gls{ge}, the size of the buffers is expressed through the amount of required memory in
    bytes (for an \gls{arq} limit of 2).}
    \label{tab:areaoverheads}
\end{table}

Table \vref{tab:areaoverheads} gives a summary of the area overhead per network interface. To put these numbers into perspective, a state-of-the-art
\gls{mpsoc} that implements a software-defined radio platform \cite{haas18sdrmpsoc} is used as a reference. They employ a relatively small hexagonal
\gls{noc} with 10 network interfaces where the maximum distance between two nodes is 3 hops. Thus, it would only require an \gls{rtb} size of 9 flits
(amounting to 168 bytes of memory) for \gls{arq} limit 2 assuming the same base network injection rate of 0.2. As their \gls{mpsoc} encompasses 24.43
million \gls{ge} of chip area and 844 kB memory \cite[4]{haas18sdrmpsoc}, the protocol would impose a total area overhead of approximately 4.4\% in
terms of \gls{ge} and 0.2\% in terms of memory.

\section{Summary}\label{sec:summaryeval}
Out of the five protocol variants, network coded \gls{iwa} has proven to perform best. It entails the lowest percentages of failing
transmissions while exhibiting a very competitive average latency. Both G2C3 and G2C4 are viable; while the former is slightly more error-prone, it
simultaneously allows for considerably higher information rates, rendering the choice between the two largely application-dependent. However, it
should be noted that the shorter authcodes employed here are not as secure as the longer \glspl{mac} used in the other protocols.

The choice of routing strategy is not as clear-cut as that of the protocol variant. The dynamic ones marginally reduce the error probability for
network coded \gls{iwa}, but also entail slightly lower information rates. Furthermore, their alleged benefit is diminished by the network load being
concentrated on the central regions of the \gls{noc}, making their selection largely dependent on the traffic generation pattern of the network. For the
investigated scenario, \gls{dor} seems like a solid choice, given its simplicity of implementation and the more evenly distributed network load.

Increasing the \gls{arq} limit from 1 to 2 has yielded a significant improvement in terms of reliability. However, this coincides with lower
information rates and slightly higher transmission latencies. Nevertheless, as a slower but successful transmission appears to be more practical than
a fast, erroneous one, the outcome is considered an improvement.

Overall, network coded interwoven authentication with dimension order routing and an \gls{arq} limit of 2 per transmission unit is inferred as the
most effective protocol. With the relatively low network saturations investigated here, G2C4 is more suitable, but G2C3 may prove advantageous for
higher loads.
